---
title: "Estimating Earnings"
author: "Abigail Edelmen, Ahmed Almotaileq, Christopher Lacrampe"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    code_folding: hide
    highlight: tango
    theme: yeti
    toc: yes
---

#### Importing the Libraries
```{r, message = FALSE, warning = FALSE}
rm(list=ls(all=TRUE)) # clears working environment
library('tidyverse')  # bundle of packages useful for datamanipulation and organization
library('stargazer')  # package useful in outputting results of statistical models
library('knitr')      # package useful for formatting markdown files to html
library('lmtest')     # has functions for BP Test
library('sandwich')   # has functions for White TestT
```

#### Importing and Cleaning the Dataset (adjusting factor levels)

```{r, results = "hide"}
dat0 <- read.csv("ACS.csv")
dat <- subset(dat0, Earnings.Past.12.Months > 0 & Employed == 1) # selects for specific portion of the data, where earnings are positive and the case is employed

sapply(dat[14], levels) # allows us to see which factors are indexed as what
sapply(dat[24], levels) # now we can manipulate the reference factors for lm (e.g. no high school for educ and white for race)

# sets no high school as default/reference factor
dat$Educational.Attainment.Reorder <- factor(dat$Educational.Attainment, levels = c("No High School Degree", "High School Degree", "Professional Degree", "Some College", "Associates Degree", "Bachelors Degree", "Masters Degree", "Doctorate"))

# sets white as default/reference factor
dat$Race.Ethnicity.Reorder <- factor(dat$Race.Ethnicity, levels = c("White", "Black", "Hispanic", "Native American", "Hawaiian", "Asian", "Biracial", "Other Race"))
```

##### Validating factor adjustments
```{r, results = "hide"}
# checking new factor levels
sapply(dat[27], levels)
sapply(dat[28], levels)
```


#### Analyzing descriptive statistics and correlation matrix for normality assumptions
```{r, results = 'asis'}
# prepare age squared variable and log earnings variable
dat$AgeSqu <- dat$Age^2

# descriptive statistics
stargazer(dat, type ='html', digits = 2)

# correlation matrix
kable(round(cor(dat[,c("Earnings.Past.12.Months", "Age", "AgeSqu")]), 2))

```

We can see that each of the variables have standard deviations unequal to zero, satisfying the LR.3. From the correlation matrix, we can see that age and age squared are highly correlated, but not perfectly correlated, satisfying the MLR.3. From analyzing the sampling techniques of the U.S. census bureau MLR.2 is satisfied. We satisfy MLR.1 in our model design below and analyze MLR.5 after describing the model:

### Preparing the base model and analyzing the coefficients
\[
earnings = \beta_0 + \beta_1 Age + \beta_2*Age^2 + \beta_3*Female + \beta_4*Education + \beta_5*Race + \epsilon
\]

```{r, results = 'asis'}
basemod <- lm(Earnings.Past.12.Months ~ Age + AgeSqu + Female + Educational.Attainment.Reorder + Race.Ethnicity.Reorder, data = dat)

stargazer(basemod, type = 'html',                                       # Displaying OLS results
          covariate.labels=c("Age","Age Squared", "Female",             # Displaying OLS results
                             "High School", "Professional Degree",      # Displaying OLS results
                             "Some College",                            # Displaying OLS results
                             "Associates", "Bachelors",                 # Displaying OLS results
                             "Masters", "Doctorate",                    # Displaying OLS results
                             "Black", "Hispanic",                       # Displaying OLS results
                             "Native American", "Hawaiian",             # Displaying OLS results
                             "Asian", "Biracial", "Other Race"),        # Displaying OLS results
          column.labels = c("basemod", "lnbasemod"),                    # Displaying OLS results
          dep.var.labels.include = FALSE,                               # Displaying OLS results
          model.numbers = FALSE,                                        # Displaying OLS results
          dep.var.caption = "Estimating Earnings"                       # Displaying OLS results
          )                                                             # Displaying OLS results
```

#### Coefficient analysis

##### basemod

1) The coefficient for Age informs us that with each increase in 1 year, annual earnings will increase by 3,866.969 dollars on average, holding all other variables constant. To test the statistical significance, we can calculate the t-value by: 3866.969/104.623 (coefficient-0/standard error) which gives us 36.96. This is more extreme than our critical value range of (-1.960, 1.960), so we can reject the null hypothesis that age is not associated with yearly earnings with 95% confidence.

2) The coefficient for Age Squared informs us that with each increase in 1 year of age, annual earnings will decrease by 76.098 * the previous level of age, holding all other variables constant. Or, using the average age of 40, earnings will decrease by 3043.92 holding all other variables constant. To test the statistical significance, we can calculate the t-value by: -38.049/1.277 which gives us -29.80. This is more extreme than our critical value range of (01.960, 1.960), so we can reject the null hypothesis that age squared is not associated with yearly earnings with 95% confidence.

3) The coefficient for Female informs us that if the person is female, annual earnings will be lower by 18,366.68 dollars relative to a male with all other variables held constant. To test the statistical significance, we can calculate the t-value by: -18366.680/396.543 which gives us -46.31. This is more extreme than our critical value range of (-1.960, 1.960), so we can reject the null hypothesis that being female is not associated with yearly earnings with 95% confidence.

4) The coefficient for High School informs us that if the highest degree attained is high school, then annual earnings is 7,332.985 dollars greater than that of an individual without a high school degree, holding all other variables constant. To test the statistical significance, we can calculate the t-value by: 7332.985/794.199 which gives us 9.23. This is more extreme than our critical value range of (-1.960, 1.960), so we can reject the null hypothesis that attaining a high school degree is not associated with yearly earnings with 95% confidence.

5) The coefficient for Professional Degree informs us that if the highest degree attained is professional in nature, then annual earnings is 103,353.80 dollars greater than that of an individual without a high school degree, holding all other variables constant. To test the statistical significance, we can calculate the t-value by: 103353.8/1540.599 which gives us 67.1. This is more extreme than our critical value range of (-1.960, 1.960), so we can reject the null hypothesis that attaining a professional degree is not associated with yearly earnings with 95% confidence.

6) The coefficient for some college informs us that if the highest level of education attained is some amount of college, then annual earnings is 13,547.70 dollars greater than that of an individual without a high school degree, holding all other variables constant. To test the statistical significance, we can calculate the t-value by: 13547.7/800.834 which gives us 16.92. This is more extreme than our critical value range of (-1.960, 1.960), so we can reject the null hypothesis that attaining some college education is not associated with yearly earnings with 95% confidence.

7) The coefficient for associated degree inform us that if the highest level of education attained is an associates degree, then annual earnings is 17,373.78 dollars greater than that of an individual without a high school degree, holding all other variables constant. To test the statistical significance, we can calculate the t-value by: 17,373.78/967.522 which gives us 17.96. This is more extreme than our critical value range of (-1.960, 1.960) so we can reject the null hypothesis that attaining an associated degree is not associated with yearly earnings with 95% confidence.

8) The coefficient for Bachelors degree informs us that if the highest level of education attained is a bachelors degree, then annual earnings is 35,296.62 dollars greater than that of an individual without a high school degree, holding all other variables constant. To test the statistical significance, we can calculate the t-value by: 35,296.62/835.661 which gives us 48.88. This is more extreme than our critical value range of (-1.960, 1.960) so we reject the null hypothesis that attaining a masters degree is not associated with yearly earnings with 95% confidence.

9) The coefficient for Masters degree informs us that if the highest level of education attained is a masters degree, then annual earnings is 48,399.95 dollars greater than that of an individual without a high school degree, holding all other variables constant. To test the statistical significance, we can calculate the t-value by: 48,399.95/990.112 which gives us 42.24. This is more extreme than our critical value range of (-1.960, 1.960) so we reject the null hypothesis that attaining a bachelors degree is not associated with yearly earnings with 95% confidence.

10) The coefficient for Doctorate degree informs us that if the highest level of education attained is a doctorate degree, then annual earnings is 63,861.32 dollars greater than that of an individual without a high school degree, holding all other variables constant. To test the statistical significance, we can calculate the t-value by: 63,861.32/1891.616 which gives us 33.76. This is more extreme than our critical value range of (-1.960, 1.960) so we reject the null hypothesis that attaining a doctorate degree is not associated with yearly earnings with 95% confidence.

11) The coefficient for identifying as Black informs us that if an individual identifies as black, then annual earnings is 7,077.63 dollars less than that of an individual who identifies as white, holding all other variables constant. To test the statistical significance, we can calculate the t-value by: -7,077.63/679.525 which gives us -10.42. This is more extreme than our critical value range of (-1.960, 1.960) so we reject the null hypothesis that identifying as black is not associated with yearly earnings with 95% confidence.

12) The coefficient for identifying as Hispanic informs us that if an individual identifies as hispanic, then annual earnings is 5,083.814 dollars less than that of an individual who identifies as white, holding all other variables constant. To test the statistical significance, we can calculate the t-value by: -5,083.814/624.605 which gives us -8.14. This is more extreme than our critical value range of (-1.960, 1.960) so we reject the null hypothesis that identifying as hispanic is not associated with yearly earnings with 95% confidence.

13) The coefficient for identifying as Native American informs us that if an individual identifies as native american, then annual earnings is 6,399.238 dollars less than that of an individual who identifies as white, holding all other variables constant. To test the statistical significance, we can calculate the t-value by: -6,399.238/2,267.882 which gives us -2.82. This is more extreme than our critical value range of (-1.960, 1.960) so we reject the null hypothesis that identifying as native american is not associated with yearly earnings with 95% confidence.

14) The coefficient for identifying as Hawaiian/Pacific Islander informs us that if an individual identifies as hawaiian/pacific islander, then annual earnings is 2,360.358 dollars less than that of an individual who identifies as white, holding all other variables constant. To test the statistical significance, we can calculate the t-value by: -2,360.358/5,754.94 which gives us -0.41. This is within our critical value range of (-1.960, 1.960) so we fail to reject the null hypothesis that identifying as hawaiian/pacific islander is not associated with yearly earnings with 95% confidence.

15) The coefficient for identifying as Asian informs us that if an individual identifies as asian, then annual earnings is 987.821 dollars more than that of an individual who identifies as white, holding all other variables constant. To test the statistical significance, we can calculate the t-value by: 987.821/916.703 which gives us 1.08. This is within our critical value range of (-1.960, 1.960) so we fail to reject the null hypothesis that identifying as asian is not associated with yearly earnings with 95% confidence.

16)  The coefficient for identifying as biracial informs us that if an individual identifies as biracial, then annual earnings is 4,439.967 dollars less than that of an individual who identifies as white, holding all other variables constant. To test the statistical significance, we can calculate the t-value by: -4,439.967/1,586.433 which gives us -2.80. This is more extreme than our critical value range of (-1.960, 1.960) so we reject the null hypothesis that identifying as biracial is not associated with yearly earnings with 95% confidence.

17) The coefficient for identifying as 'other' informs us that if an individual identifies as 'other', then annual earnings is 2,725.607 dollars less than that of an individual who identifies as white, holding all other variables constant. To test the statistical significance, we can calculate the t-value by: -2,725.607/6,167.217 which gives us -0.44. This is within our critical value range of (-1.960, 1.960) so we fail to reject the null hypothesis that identifying as 'other' is not associated with yearly earnings with 95% confidence.

18) The F Statistic of 1,027.581 is statistically significant with degrees of freedom (17, 46053). The adjusted R squared value is 0.275, which prompts the notion that 27.5% of the variation in annual earnings is explained by the variation of the regressors.

*For the base model, the degrees of freedom are n(46071)-k(17)-1 or 46053. Using our t-table we get a critical value of about 1.960 at the 5% level. Furthermore, conclusions are only applicable to the representative sample of positive, employed earners in the United States.

### Applying the base model: Part I

1) Estimated Regression Equation

$\begin{aligned}
\hat earnings &= -56,280.99 + 3,866.969*Age -38.049*Age^2 -18,366.680*Female \dots \\
\hat earnings &= ...  + 7,332.985*High School + 13,353.8*Professional Degree \dots\\
\hat earnings &= ...   + 13,547.770*Some College  + 17,373.78*Associates + 35,296.620*Bachelors \dots \\
\hat earnings &= ... + 48,399.95*Masters + 63,861.320*Doctorate - 7,077.630*Black \dots \\
\hat earnings &= ... -5,083.814*Hispanic - 6,399.328*Native American -2,360.358*Hawaiian \dots \\
\hat earnings &= ... + 987.821*Asian - 4,439.967*Biracial - 2,725.607*Other Race + \epsilon
\end{aligned}$

2) The relationship between age and earnings is a negative and convex quadratic equation holding all other variables constant:

$\begin{aligned}
\Delta \hat earnings &= 3,866.969 - 76.1*(Age)
\end{aligned}$

From transitioning to age 20-21 we can expect an increase in annual earnings of $2,268.87 holding all other variables constant
From transitioning to age 40-41 we can expect an increase in annual earnings of $746.87 holding all other variables constant

3) Estimating the earnings for a 43 year old asian female without a known level of education (relative to a white male with the same age)

$\begin{aligned}
\hat earnings &= -56,280.99 + 3,866.969*Age - 38.049*Age^2 - 18,366.680*female + 987.821* Asian \\
\hat earnings &= \$22,225.55 | Age = 43, Female = 1, Asian = 1
\end{aligned}$

### Further Applications and Heteroskedasticity: Part II
(we know there's a hetero because as education level increases, the variance of that education level increases (non-constant variance))

#### A) BP test
```{r, results = "hide"}
n <- length(dat$u2)
heterotest <- lm(resid(basemod)^2~Age + AgeSqu + Female + Educational.Attainment.Reorder + Race.Ethnicity.Reorder, data = dat)

u2model.r2 <- summary(heterotest)$r.squared
bp <- n*u2model.r2
bp

1 - pchisq(bp, df=5)
```
```{r}
bptest(basemod)
```

The results from the BP test indicate heteroskedasticity in the model where:

$\begin{aligned}
H_0: VAR(u_i|x_i) &= \sigma^2 \\
H_a: VAR(u_i|x_i) &= \sigma^2_i
\end{aligned}$

Our output results are statistically significant at the 5% value so we can reject the null hypothesis of homoskedasticity. Thus the model fails to satisfy MLR.5 so we are unable to infer the effects of the coefficients at the population level. However, the model may still be BLUE as long as MLR.1-4 remain satisfied.


#### B) White Test
```{r, results = "hide"}
u2model2<- lm(resid(basemod)^2  ~fitted(basemod) + I(fitted(basemod)^2),  data=dat)
dat$hhat<-fitted(u2model2)
u2model2.r2 <- summary(u2model2)$r.squared  #access r^2 value from model
white<- n*u2model2.r2
white
1 - pchisq(white, df=2)
```

```{r}
bptest(basemod, ~fitted(basemod)+I(fitted(basemod)^2))
```
The results from the white test fail to reject the null hypothesis in the model where:

$\begin{aligned}
H_0: VAR(u_i|x_i) &= \sigma^2 \\
H_a: VAR(u_i|x_i) &= \sigma^2_i
\end{aligned}$

We fail to reject the null hypothesis at the 5% level so our results appear to be homoskedastic.

#### Final Conclusion about homoskedasticity

Because one of our tests (BP) rejected the homoskedastic hypothesis, we concloude that the basemode likely includes a heteroskedastic presence.

#### C) Robustness and heteroskedastic adjustments
```{r, results = "asis"}
robustmod <- coeftest(heterotest, sandwich) # robust coefficients

# If we know the form of the hetero as a function of age
WLS.mod <- lm(Earnings.Past.12.Months ~ Age + AgeSqu + Female + Educational.Attainment.Reorder + Race.Ethnicity.Reorder, weight=1/Age, data = dat)

#Case 2: Given we do not know the variance format, we use the more general way of finding the weight, so called FGLS
#FGLS: estimation of the variance functin

dat$u2<-log(resid(basemod)^2)

varreg<- lm(u2~Age+AgeSqu+ Female + Educational.Attainment.Reorder +Race.Ethnicity.Reorder, data=dat)

w<- 1/exp(fitted(varreg))

FGLS.mod <- lm(Earnings.Past.12.Months ~ Age+AgeSqu+ Female + Educational.Attainment.Reorder + Race.Ethnicity.Reorder, weight=w, data = dat)



stargazer(basemod,WLS.mod, FGLS.mod, robustmod, type="html",
          covariate.labels=c("Age","Age Squared", "Female", 
                             "High School", "Professional Degree",      
                             "Some College",                           
                             "Associates", "Bachelors",                
                             "Masters", "Doctorate",                    
                             "Black", "Hispanic",                      
                             "Native American", "Hawaiian",            
                             "Asian", "Biracial", "Other Race"),                          
          column.labels = c("basemod", "WLS", "FGLS", "robust"),     
          dep.var.labels.include = FALSE,                              
          model.numbers = FALSE,                                       
          dep.var.caption = "Estimating Earnings"                      
          )                                                            
                             
```

Comparing the base model with the weighted least squares model and feasible generalized least squares model seems to have limited impact on the significance of the coefficients, more specifically, the significance of the biracial coefficient decreases in the WLS model. Comparing the base model with the robust model also yields similar results, where the majority of the coefficients retain their significance level--with the exception of the age squared variable.

#### D) Repeating the process with log(earnings)
```{r}
# creating the log.mod
dat$log.Earnings.Past.12.Months <- log(dat$Earnings.Past.12.Months)
log.mod <- lm(log.Earnings.Past.12.Months ~ Age+AgeSqu+ Female + Educational.Attainment.Reorder +Race.Ethnicity.Reorder, data = dat)
```

#### BP test
```{r, results = "hide"}
n <- length(dat$u2)
log.heterotest <- lm(resid(log.mod)^2~Age + AgeSqu + Female + Educational.Attainment.Reorder + Race.Ethnicity.Reorder, data = dat)

log.u2model.r2 <- summary(log.heterotest)$r.squared
bp <- n*log.u2model.r2
bp

1 - pchisq(bp, df=5)
```

```{r}
bptest(log.mod)
```


The results from the BP test indicate heteroskedasticity in the log model where:

$\begin{aligned}
H_0: VAR(u_i|x_i) &= \sigma^2 \\
H_a: VAR(u_i|x_i) &= \sigma^2_i
\end{aligned}$

Our output results are statistically significant at the 5% value so we can reject the null hypothesis of homoskedasticity. Thus the model fails to satisfy MLR.5 so we are unable to infer the effects of the coefficients at the population level. However, the model may still be BLUE as long as MLR.1-4 remain satisfied.

#### White test
```{r, results = "hide"}
log.u2model2<- lm(resid(log.mod)^2  ~fitted(log.mod) + I(fitted(log.mod)^2),  data=dat)
dat$hhat<-fitted(log.u2model2)
log.u2model2.r2 <- summary(log.u2model2)$r.squared  #access r^2 value from model
white<- n*log.u2model2.r2
white
1 - pchisq(white, df=2)
```

```{r}
bptest(log.mod, ~fitted(log.mod)+I(fitted(log.mod)^2))
```

The results from the White test indicate heteroskedasticity in the log model where:

$\begin{aligned}
H_0: VAR(u_i|x_i) &= \sigma^2 \\
H_a: VAR(u_i|x_i) &= \sigma^2_i
\end{aligned}$

Our output results are statistically significant at the 5% value so we can reject the null hypothesis of homoskedasticity. Thus the model fails to satisfy MLR.5 so we are unable to infer the effects of the coefficients at the population level. However, the model may still be BLUE as long as MLR.1-4 remain satisfied.

#### Conclusions about heteroskedasticity
Since both the BP test and white test reject the null hypothesis of homoskedasticity, we conclude that heteroskedasticity is likely present.

#### Robustness and Heteroskedastic Adjustments
```{r, results = "asis"}
log.robustmod <- coeftest(log.heterotest, sandwich) # robust coefficients

# If we know the form of the hetero as a function of age
log.WLS.mod <- lm(log.Earnings.Past.12.Months ~ Age + AgeSqu + Female + Educational.Attainment.Reorder + Race.Ethnicity.Reorder, weight=1/Age, data = dat)

#Case 2: Given we do not know the variance format, we use the more general way of finding the weight, so called FGLS
#FGLS: estimation of the variance functin

dat$logu2<-log(resid(log.mod)^2)

log.varreg<- lm(logu2~Age+AgeSqu+ Female + Educational.Attainment.Reorder +Race.Ethnicity.Reorder, data=dat)

w<- 1/exp(fitted(log.varreg))

log.FGLS.mod <- lm(log.Earnings.Past.12.Months ~ Age+AgeSqu+ Female + Educational.Attainment.Reorder + Race.Ethnicity.Reorder, weight=w, data = dat)



stargazer(log.mod, log.WLS.mod, log.FGLS.mod, log.robustmod, type="html",
          covariate.labels=c("Age","Age Squared", "Female", 
                             "High School", "Professional Degree",      
                             "Some College",                           
                             "Associates", "Bachelors",                
                             "Masters", "Doctorate",                    
                             "Black", "Hispanic",                      
                             "Native American", "Hawaiian",            
                             "Asian", "Biracial", "Other Race"),                          
          column.labels = c("log.mod", "log.WLS", "log.FGLS", "log.robust"),     
          dep.var.labels.include = FALSE,                              
          model.numbers = FALSE,                                       
          dep.var.caption = "Estimating Earnings"
          )
```                             

Comparing the log model to the WLS and FGLS models leads to an adjustment of the statistical significance for the coefficients for hispanic and for asian dummy variables. Comparing the logmod to the robust model, we can see that the statistical significance for some of the variables is reduced. For example, the statistical significance of the high school, Professional Degree, Some College, Black, Native American, and Native American categories are reduced. However, the statistical significance of the other race, and Hawaiian categories increases.